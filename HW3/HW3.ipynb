{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3\n",
    "All previous instructions hold. In addition, if you are using GPU, you must check that your code also runs on a CPU. \n",
    "\n",
    "**Make sure you use the best practices you learned in class**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (12.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network - Classifiying CIFAR-10 (30 points)\n",
    "\n",
    "So far we had to manually implement both the forward and backward passes of our neural network. Manually implementing the backward pass is not a big deal for a small two-layer network, but can quickly get very messy for large complex networks.\n",
    "\n",
    "Thankfully, we can use **automatic differentiation** to automate the computation of backward passes in neural networks. The autograd package in PyTorch provides exactly this functionality. When using autograd, the forward pass of your network will define a computational graph. Nodes in the graph will be Tensors,\n",
    "and edges will be functions that produce output Tensors from input Tensors. Backpropagating through this graph then allows you to easily compute gradients.\n",
    "\n",
    "If we want to compute gradients with respect to some Tensor, then we set `requires_grad=True` when constructing that Tensor. Any PyTorch operations on that Tensor will cause a computational graph to be constructed, allowing us to later perform backpropagation through the graph. If `x` is a Tensor with `requires_grad=True`, then after backpropagation `x.grad` will be another Tensor holding the gradient of `x`.\n",
    "\n",
    "Sometimes you may wish to prevent PyTorch from building computational graphs when performing certain operations on Tensors with `requires_grad=True`; for example, we usually don't want to backpropagate through the weight update steps when evaluating a neural network. In such scenarios we can use the `torch.no_grad()` context manager to prevent the construction of a computational graph.\n",
    "\n",
    "In this exercise, you will accomplish the following:\n",
    "1. Train a convolutional network using PyTorch.\n",
    "2. Evaluate your model using a confusion matrix.\n",
    "3. Solve the localization task using regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 170467328/170498071 [25:26<00:00, 134120.26it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "170500096it [25:40, 134120.26it/s]                               "
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape:  torch.Size([3, 32, 32])\n",
      "     horse       deer      horse       frog\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0))) # plt accepts images in the format (w,h,c)\n",
    "    \n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "print(\"Image shape: \", images[0].shape)\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images[:4]))\n",
    "# print labels\n",
    "print(' '.join('%10s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct a CNN in PyTorch - 20 points\n",
    "\n",
    "In the following class, initiate your different layers in the `__init__` method and define your architecture in the `forward` method. Make sure the `forward` method has a single return value. \n",
    "\n",
    "1. Make good use of the documentation and experiment will different layers, activations and architectures, batch sizes, regularization, filter sizes, dimensions, number of layers and whatever you learned in class. \n",
    "2. Use your intuition from the previous exercises and additional sources such as the Piazza, papers, etc. - do not try to perform a massive grid search.\n",
    "3. **Include only your chosen architecture**. During experimentation, you may add as many cells as you need. Make sure to delete them before submission.\n",
    "4. Make sure your code runs reasonably fast (~30 minutes on CPU and ~5 minutes on GPU).\n",
    "5. Use the best architecture you find and train it for 5-10 epochs. \n",
    "6. Explain why you chose that architecture and why you think it performs better than other networks you tried. Cite papers, blogs, MOOCs, online guides and every other source you used during optimization.\n",
    "7. Visualize the loss and accuracy of your network during training. You can use matplotlib or tensorboard.\n",
    "8. **You should get close to 75% accuracy, explain you results and include visualizations for the full 20 points**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        #############################################################################\n",
    "        # TO DO:                                                                    #\n",
    "        # Initiate the different layers you wish to use in your network.            #\n",
    "        # This method has no return value.                                          #\n",
    "        #############################################################################\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        #############################################################################\n",
    "        #                             END OF YOUR CODE                              #\n",
    "        #############################################################################\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #############################################################################\n",
    "        # TO DO:                                                                    #\n",
    "        # Define the forward propagation. You need to pass an image through the     #\n",
    "        # network and obtain class predictions.                                     #\n",
    "        # This function returns the predication of your model.                      #\n",
    "        #############################################################################\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        #############################################################################\n",
    "        #                             END OF YOUR CODE                              #\n",
    "        #############################################################################\n",
    "\n",
    "net = Net()\n",
    "criterion = None\n",
    "optimizer = None\n",
    "#############################################################################\n",
    "# TO DO:                                                                    #\n",
    "# Define the loss function and optimizer.                                   # \n",
    "#############################################################################\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "#############################################################################\n",
    "#                             END OF YOUR CODE                              #\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "# TO DO:                                                                    #\n",
    "# Define the training loop as seen in class and as demonstrated in the      #\n",
    "# documentation. Note, if you are using GPU, make sure your code runs on    #\n",
    "# CPU also. Code that cannot run will not be tested.                        # \n",
    "#############################################################################\n",
    "pass\n",
    "#############################################################################\n",
    "#                             END OF YOUR CODE                              #\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "imshow(torchvision.utils.make_grid(images[:4]))\n",
    "print('GroundTruth: ', ' '.join('%7s' % classes[labels[j]] for j in range(4)))\n",
    "outputs = net(images)\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "print('Predicted:   ', ' '.join('%7s' % classes[predicted[j]]for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation - 10 points\n",
    "\n",
    "Calculate the model accuracy and print a confusion matrix where in y axis represents the real category and the x axis represents the predicted category. You are allowed to use loops. **Explain the results**: what can you learn from the confusion matrix? Why do you need additional evaluation methods other than accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = np.zeros([10,10], int)\n",
    "model_accuracy = 0\n",
    "#############################################################################\n",
    "# TO DO:                                                                    #\n",
    "# Define the evaluation loop as seen in class and as demonstrated in the    #\n",
    "# documentation and use the confusion matrix to evaluate your model.        # \n",
    "#############################################################################\n",
    "pass\n",
    "#############################################################################\n",
    "#                             END OF YOUR CODE                              #\n",
    "#############################################################################\n",
    "print('Model accuracy on {0} test images: {1:.2f}%'.format(len(testset), model_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(8,6))\n",
    "ax.matshow(confusion_matrix, aspect='auto', vmin=0, vmax=1000, cmap=plt.get_cmap('Blues'))\n",
    "plt.ylabel('Actual Category')\n",
    "plt.yticks(range(10), classes)\n",
    "plt.xlabel('Predicted Category')\n",
    "plt.xticks(range(10), classes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Localization as Regression (60 points)\n",
    "\n",
    "State of the art accuracy on CIFAR10 is currently ~99% on the test set. In the next part, we will use a well known architecture called ResNet18 that was trained on ImageNet, a dataset far more rich than CIFAR10. ImageNet has 1,000 classes and 1,000,000 images and the pretrained ResNet18 available in PyTorch correctly classifies ~70% of the test set. In this part, we will use the features extracted from ResNet18 to localize and classify images of cats and dogs. \n",
    "\n",
    "Using a pretrained network as a building block for a more complicated task is at the heart of neural networks today. By leveraging the features ResNet18 extracts, we can train a model that can correctly classify and localize cats and dogs using very few images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from data.dataloader import *\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import collections\n",
    "import time\n",
    "import copy\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load ResNet18 with the pretrained weights, use the following line. You are welcome to try different architectures, however they might require different input sizes or normalization.\n",
    "\n",
    "The first time you run this cell the weights will be downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18 = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet takes as input images of size (224,224). We will use PyTorch Transforms to change the size of the images. When ResNet18 was trained on ImageNet, the images were normalized using the mean and standard deviation of the images. In order to properly use the weights, we will use the same normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        Rescale((224,224)),\n",
    "        ToTensor(),\n",
    "        Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # normalizing according to imagenet\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        Rescale((224,224)),\n",
    "        ToTensor(),\n",
    "        Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "root_dir = \"data/animals/\"\n",
    "datasets = {x: VOCDetection(root_dir, image_set=x, transform=data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(datasets[x], batch_size=32, shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(datasets[x]) for x in ['train', 'val']}\n",
    "classes = datasets['train'].classes\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(dataset_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of training data\n",
    "sample = next(iter(dataloaders['train']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img, label, bbox):\n",
    "    image = np.copy(img[0])\n",
    "    image = np.transpose(image, (1, 2, 0))\n",
    "    image *= np.array([0.229, 0.224, 0.225])\n",
    "    image += np.array([0.485, 0.456, 0.406])\n",
    "    label = label[0]\n",
    "    bbox = bbox[0]\n",
    "    plt.figure();\n",
    "    fig, ax = plt.subplots(1, figsize=(12,9));\n",
    "    ax.imshow(image);\n",
    "    x1, y1, x2, y2 = bbox.numpy().reshape(-1) * 224\n",
    "    box_w, box_h = np.abs(x2-x1), np.abs(y2-y1)\n",
    "    bbox = patches.Rectangle((x1, y1), box_w, box_h, linewidth=2, \n",
    "                             edgecolor='r', facecolor='none');\n",
    "    ax.add_patch(bbox);\n",
    "    ax.annotate(classes[label], (x1, y1), color='r', fontsize=14);\n",
    "\n",
    "imshow(sample['image'],sample['label'],sample['bbox'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNN, self).__init__()\n",
    "        #############################################################################\n",
    "        # TO DO:                                                                    #\n",
    "        # Load the pretrained ResNet-18 network and replace the top fully connected #\n",
    "        # layer, so we could pass the features of the network and not the only      #\n",
    "        # the classification layer which carries significantly less information.    #\n",
    "        # Afterwards, create a new sequential model with the remaining layers of    #\n",
    "        # the pretrained network. Next, define two additional models that take as   #\n",
    "        # input the extracted features and output the class scores and bounding box #\n",
    "        # coordinates.                                                              #\n",
    "        # This function has no return value.                                        #\n",
    "        #############################################################################\n",
    "        pass\n",
    "        #############################################################################\n",
    "        #                             END OF YOUR CODE                              #\n",
    "        #############################################################################\n",
    "    \n",
    "    def forward(self, images):\n",
    "        #############################################################################\n",
    "        # TO DO:                                                                    #\n",
    "        # Define the forward propagation. You need to pass an image through the     #\n",
    "        # network and extract the feature vector. In this case, when using a        #\n",
    "        # predefined network, you don't want to change it's weights.                #\n",
    "        # The rest of the layers you defined should accepts gradients for them to   #\n",
    "        # improve during training.                                                  #\n",
    "        # This function returns a class predication and a bounding box coordinates. #\n",
    "        #############################################################################\n",
    "        pass\n",
    "        #############################################################################\n",
    "        #                             END OF YOUR CODE                              #\n",
    "        #############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guidelines\n",
    "\n",
    "1. Complete the `train_model` function in the cell below. This function takes as input the model and additional hyper-parameters, and outputs the best model found on the validation set. \n",
    "2. To babysit the learning process, **you must track the classification accuracy, IoU score and loss on the training and validation datasets and visualize them** (using tensorboard or matplotlib). I have included an implementation of the IoU metric in the file `data\\dataloader.py`.\n",
    "3. Do not perform a massive grid search. Use papers, blogs, MOOCs and online guides to research best hyper-parameters for your model. Once you chose your model. Explain why you chose that architecture and why you think it performs better than other networks you tried - use citation from sources you used.\n",
    "4. You are encouraged to try Google Colab or a free AWS / Google Cloud Platform / Azure available for students. If you have an CUDA capable GPU at home - you are welcome to use it. Training one of our networks on a Core i7 for 10 epochs took 5 minutes and reached 99% classification accuracy and over 0.75 IoU score on the validation set (this took less than a minute using a RTX 2080 Ti GPU).\n",
    "5. **Include only your chosen architecture**. During experimentation, you may add as many cells as you need. Make sure to delete them before submission.\n",
    "6. Training large neural networks may take a while. Make sure your code runs reasonably fast (~30 minutes on CPU and ~5 minutes on GPU).\n",
    "7. **In order to get full marks for this section, reach at least 98% classification accuracy and a IOU score of at least 0.70 on the validation set using a single model, explain the results and include visualizations**.\n",
    "8. You are given a general skeleton for the training function. Feel free to use any different structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion_cls, criterion_bbox, optimizer, scheduler=None, num_epochs=5):\n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict()) # this is how a model is copied\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0   # total loss of the network at each epoch\n",
    "            running_corrects = 0 # number of correct predictions\n",
    "            iou = 0.0            # IoU score\n",
    "            \n",
    "            # Iterate over data.\n",
    "            for sample in dataloaders[phase]:\n",
    "                #############################################################################\n",
    "                # TO DO:                                                                    #\n",
    "                # Extract the data from the dataloader, calculate the predictions of your   #\n",
    "                # network and calculate the loss of the classification and bounding box     #\n",
    "                # prediction. When in training mode, back-prop and update the weights.      #\n",
    "                # At each epoch, calculate the test and train accuracy and IoU.             #\n",
    "                # This function returns the best model in terms of accuracy.                #\n",
    "                #############################################################################\n",
    "                pass\n",
    "                #############################################################################\n",
    "                #                             END OF YOUR CODE                              #\n",
    "                #############################################################################\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            iou = iou.item() / dataset_sizes[phase]\n",
    "            \n",
    "            print('{} Loss: {:.4f}  |  Acc: {:.4f}  |  IOU: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc, iou))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose your optimizer and the loss functions for the classification and bounding box regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "cnn = CNN(2)\n",
    "cnn = cnn.to(device)\n",
    "\n",
    "criterion_cls = None\n",
    "criterion_bbox = None\n",
    "optimizer = None\n",
    "#############################################################################\n",
    "#                           START OF YOUR CODE                              #\n",
    "#############################################################################\n",
    "pass\n",
    "#############################################################################\n",
    "#                             END OF YOUR CODE                              #\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "best_model = train_model(cnn, criterion_cls, criterion_bbox, optimizer, num_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you are pleased with your results, see how your model can predict and localize cats and dogs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of validation data\n",
    "sample = next(iter(dataloaders['val']))\n",
    "with torch.no_grad():\n",
    "    images = sample['image']\n",
    "    images = images.to(device)\n",
    "    label_pred, bbox_pred = best_model(images)\n",
    "    _, label_pred = torch.max(label_pred, 1)\n",
    "imshow(sample['image'], label_pred.cpu(), bbox_pred.cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your visualizations here (IoU / Accuracy / Loss on training and validation datasets as a function of the epoch). Only visualize the results of your best model. If you want to paste an image in the notebook (such as png), make sure you include it in your submission. If you used Tensorboard, make sure you include the tfevent files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
